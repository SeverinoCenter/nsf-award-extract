{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "#show all columnsdf\n",
    "#ignore warnings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 9000)\n",
    "import numpy as np\n",
    "import os, sys\n",
    "import importlib\n",
    "import yaml, json\n",
    "from pathlib import Path\n",
    "base=Path('../Data/patents/assignees')\n",
    "inst=Path('../Data/institutions/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Define base directory\n",
    "base = Path('../Data/patent/assignee')\n",
    "\n",
    "# Get all CSV files in the directory\n",
    "csv_files = list(base.glob(\"*.csv\"))\n",
    "\n",
    "# Dictionary to store sampled dataframes\n",
    "sheets = {}\n",
    "\n",
    "# Load a sample of 1000 records from each CSV\n",
    "for file in csv_files:\n",
    "    try:\n",
    "        df = pd.read_csv(file, nrows=1000)\n",
    "        sheets[file.stem] = df  # Store dataframe with file name (without extension) as key\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {file}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Institution_OrgUEINum_C</th>\n",
       "      <th>Sum</th>\n",
       "      <th>Count</th>\n",
       "      <th>Institution_Name_C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GNJ7BBP73WE9</td>\n",
       "      <td>2.013853e+09</td>\n",
       "      <td>4689</td>\n",
       "      <td>Regents of the University of Michigan - Ann Arbor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HD1WMN6945W6</td>\n",
       "      <td>2.095012e+09</td>\n",
       "      <td>4214</td>\n",
       "      <td>University of Washington</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Y8CWNJRCNN91</td>\n",
       "      <td>2.623375e+09</td>\n",
       "      <td>4069</td>\n",
       "      <td>University of Illinois at Urbana-Champaign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NPM2J7MSCF61</td>\n",
       "      <td>1.487659e+09</td>\n",
       "      <td>3861</td>\n",
       "      <td>Pennsylvania State Univ University Park</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GS3YEVSS12N6</td>\n",
       "      <td>1.879913e+09</td>\n",
       "      <td>3758</td>\n",
       "      <td>University of California-Berkeley</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17400</th>\n",
       "      <td>Butler Annie</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0</td>\n",
       "      <td>Butler Annie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17401</th>\n",
       "      <td>Ray Emily A</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0</td>\n",
       "      <td>Ray Emily A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17402</th>\n",
       "      <td>Herbold Craig W</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0</td>\n",
       "      <td>Herbold Craig W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17403</th>\n",
       "      <td>Swedish Health Services</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0</td>\n",
       "      <td>Swedish Health Services</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17404</th>\n",
       "      <td>Saporito                Ralph          A</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0</td>\n",
       "      <td>Saporito                Ralph          A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17405 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Institution_OrgUEINum_C           Sum  Count  \\\n",
       "0                                  GNJ7BBP73WE9  2.013853e+09   4689   \n",
       "1                                  HD1WMN6945W6  2.095012e+09   4214   \n",
       "2                                  Y8CWNJRCNN91  2.623375e+09   4069   \n",
       "3                                  NPM2J7MSCF61  1.487659e+09   3861   \n",
       "4                                  GS3YEVSS12N6  1.879913e+09   3758   \n",
       "...                                         ...           ...    ...   \n",
       "17400                              Butler Annie  0.000000e+00      0   \n",
       "17401                               Ray Emily A  0.000000e+00      0   \n",
       "17402                           Herbold Craig W  0.000000e+00      0   \n",
       "17403                   Swedish Health Services  0.000000e+00      0   \n",
       "17404  Saporito                Ralph          A  0.000000e+00      0   \n",
       "\n",
       "                                      Institution_Name_C  \n",
       "0      Regents of the University of Michigan - Ann Arbor  \n",
       "1                               University of Washington  \n",
       "2             University of Illinois at Urbana-Champaign  \n",
       "3                Pennsylvania State Univ University Park  \n",
       "4                      University of California-Berkeley  \n",
       "...                                                  ...  \n",
       "17400                                       Butler Annie  \n",
       "17401                                        Ray Emily A  \n",
       "17402                                    Herbold Craig W  \n",
       "17403                            Swedish Health Services  \n",
       "17404           Saporito                Ralph          A  \n",
       "\n",
       "[17405 rows x 4 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(inst/'institutions.csv')\n",
    "ass = Path('../Data/patent/assignee/assignee.csv')\n",
    "df_a=pd.read_csv(ass)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ee=df_a.value_counts('ee_name')\n",
    "df_ee=df_ee.reset_index()\n",
    "df_ee.sort_values('ee_name',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ee.to_csv('../Data/patents/entities.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ee.reset_index(, inplace=True)\n",
    "\n",
    "#df_ee.sort_values('ee_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          164781\n",
       "1          130758\n",
       "2           75652\n",
       "3           59364\n",
       "4           58294\n",
       "            ...  \n",
       "1321777         1\n",
       "1321778         1\n",
       "1321779         1\n",
       "1321780         1\n",
       "1321781         1\n",
       "Name: count, Length: 1321782, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "def load_model():\n",
    "    \"\"\"Load a pre-trained SentenceTransformer model.\"\"\"\n",
    "    return SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "def encode_texts(model, texts):\n",
    "    \"\"\"Encode a list of texts into embeddings using a SentenceTransformer model.\"\"\"\n",
    "    return model.encode(texts, convert_to_tensor=True)\n",
    "\n",
    "def find_closest_match(name, model, search_space_embeddings, search_space_df, return_columns):\n",
    "    \"\"\"Find the closest match for a given name using cosine similarity.\"\"\"\n",
    "    query_embedding = model.encode(name, convert_to_tensor=True)\n",
    "    similarities = torch.nn.functional.cosine_similarity(query_embedding, search_space_embeddings, dim=1)\n",
    "    closest_idx = torch.argmax(similarities).item()\n",
    "    \n",
    "    result = {'Similarity_Score': similarities[closest_idx].item()}\n",
    "    for col in return_columns:\n",
    "        result[col] = search_space_df.iloc[closest_idx][col]\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Load model\n",
    "model = load_model()\n",
    "\n",
    "# Load and encode institution names in the search space\n",
    "cs_embeddings = encode_texts(model, cs['INSTNM'].tolist())\n",
    "\n",
    "# Define columns to return\n",
    "return_columns = ['INSTNM', 'UNITID', 'OPEID', 'OPEID6']\n",
    "\n",
    "# Initialize results storage\n",
    "results = []\n",
    "batch_size = 100  # Save progress every 100 records\n",
    "\n",
    "# Iterate over the input DataFrame and find closest matches\n",
    "for i, (name, org_uei) in enumerate(zip(df['Institution_Name_C'], df['Institution_OrgUEINum_C']), start=1):\n",
    "    match_result = find_closest_match(name, model, cs_embeddings, cs, return_columns)\n",
    "    match_result.update({'Institution_Name_C': name, 'Institution_OrgUEINum_C': org_uei, 'Similarity_Score': match_result['Similarity_Score']})\n",
    "    results.append(match_result)\n",
    "    \n",
    "    # Save intermediate results\n",
    "    if i % batch_size == 0:\n",
    "        print(f\"Processed {i} records, saving progress...\")\n",
    "        pd.DataFrame(results).to_csv(f\"progress_{i}.csv\", index=False)\n",
    "\n",
    "# Final save\n",
    "final_df = pd.DataFrame(results)\n",
    "final_df.to_csv(\"final_results.csv\", index=False)\n",
    "\n",
    "# Merge results into the original DataFrame\n",
    "df = df.merge(final_df, on=['Institution_Name_C', 'Institution_OrgUEINum_C'], how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bv/2rb8dc7100ncxqhclz10zf5c0000gn/T/ipykernel_61981/756587973.py:8: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
      "  value = value.apply(pd.to_numeric, errors='ignore')\n",
      "Exception ignored in: <function ZipFile.__del__ at 0x102d06a70>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jasonkuruzovich/anaconda3/envs/newdeep/lib/python3.10/zipfile.py\", line 1834, in __del__\n",
      "    self.close()\n",
      "  File \"/Users/jasonkuruzovich/anaconda3/envs/newdeep/lib/python3.10/zipfile.py\", line 1851, in close\n",
      "    self.fp.seek(self.start_dir)\n",
      "ValueError: seek of closed file\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outputting final Excel file: sampled_assignees.xlsx\n",
      "Outputting sheet: assignment\n",
      "Outputting sheet: assignee\n",
      "Outputting sheet: assignor\n",
      "Outputting sheet: documentid\n",
      "Outputting sheet: documentid_admin\n",
      "Outputting sheet: assignment_conveyance\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define function to write to Excel\n",
    "def write_excel(outpath, outfile, sheets):\n",
    "    print(\"Outputting final Excel file:\", str(outfile))\n",
    "    with pd.ExcelWriter(outpath / outfile) as writer:\n",
    "        for key, value in sheets.items():\n",
    "            if len(value) < 1048576:\n",
    "                print(\"Outputting sheet:\", key)\n",
    "                value = value.apply(pd.to_numeric, errors='ignore')\n",
    "                value.to_excel(writer, sheet_name=key, index=True)\n",
    "            else:\n",
    "                print(\"Too large, saving CSV:\", key)\n",
    "                value.to_csv(outpath / f\"{key}.csv\", index=False)\n",
    "\n",
    "# Define output path and file name\n",
    "output_path = Path('../Data/patents/assignees/')\n",
    "output_file = 'sampled_assignees.xlsx'\n",
    "\n",
    "# Ensure output directory exists\n",
    "output_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Write to Excel\n",
    "write_excel(output_path, output_file, sheets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 410/835 [57:15<2:55:35, 24.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error downloading 2016/ipg161227.zip: ('Connection broken: IncompleteRead(41973011 bytes read, 82006373 more expected)', IncompleteRead(41973011 bytes read, 82006373 more expected))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 411/835 [58:34<4:35:19, 38.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error downloading 2016/ipg161115.zip: ('Connection broken: IncompleteRead(105838161 bytes read, 29932021 more expected)', IncompleteRead(105838161 bytes read, 29932021 more expected))\n",
      "Error downloading 2017/ipg170103.zip: ('Connection broken: IncompleteRead(38100938 bytes read, 79784179 more expected)', IncompleteRead(38100938 bytes read, 79784179 more expected))\n",
      "Error downloading 2016/ipg161213.zip: ('Connection broken: IncompleteRead(90583436 bytes read, 7707146 more expected)', IncompleteRead(90583436 bytes read, 7707146 more expected))\n",
      "Error downloading 2016/ipg161220.zip: ('Connection broken: IncompleteRead(75239300 bytes read, 8861054 more expected)', IncompleteRead(75239300 bytes read, 8861054 more expected))\n",
      "Error downloading 2017/ipg170110.zip: ('Connection broken: IncompleteRead(24453418 bytes read, 101837122 more expected)', IncompleteRead(24453418 bytes read, 101837122 more expected))\n",
      "Error downloading 2016/ipg161206.zip: ('Connection broken: IncompleteRead(111130483 bytes read, 20246278 more expected)', IncompleteRead(111130483 bytes read, 20246278 more expected))\n",
      "Error downloading 2016/ipg161129.zip: ('Connection broken: IncompleteRead(110089243 bytes read, 12135752 more expected)', IncompleteRead(110089243 bytes read, 12135752 more expected))\n",
      "Error downloading 2017/ipg170117.zip: ('Connection broken: IncompleteRead(10777924 bytes read, 76264559 more expected)', IncompleteRead(10777924 bytes read, 76264559 more expected))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 412/835 [1:03:06<11:56:32, 101.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error downloading 2016/ipg161122.zip: ('Connection broken: IncompleteRead(102488842 bytes read, 22635997 more expected)', IncompleteRead(102488842 bytes read, 22635997 more expected))\n",
      "Error downloading 2017/ipg170307.zip: ('Connection broken: IncompleteRead(5536666 bytes read, 125376512 more expected)', IncompleteRead(5536666 bytes read, 125376512 more expected))\n",
      "Error downloading 2017/ipg170404.zip: ('Connection broken: IncompleteRead(10422522 bytes read, 99249135 more expected)', IncompleteRead(10422522 bytes read, 99249135 more expected))\n",
      "Error downloading 2017/ipg170328.zip: ('Connection broken: IncompleteRead(9695546 bytes read, 121275125 more expected)', IncompleteRead(9695546 bytes read, 121275125 more expected))\n",
      "Error downloading 2017/ipg170418.zip: ('Connection broken: IncompleteRead(29727266 bytes read, 108146572 more expected)', IncompleteRead(29727266 bytes read, 108146572 more expected))\n",
      "Error downloading 2017/ipg170425.zip: ('Connection broken: IncompleteRead(4386947 bytes read, 121738194 more expected)', IncompleteRead(4386947 bytes read, 121738194 more expected))\n",
      "Error downloading 2017/ipg170411.zip: ('Connection broken: IncompleteRead(44409410 bytes read, 89426577 more expected)', IncompleteRead(44409410 bytes read, 89426577 more expected))\n",
      "Error downloading 2017/ipg170502.zip: ('Connection broken: IncompleteRead(14174481 bytes read, 110495892 more expected)', IncompleteRead(14174481 bytes read, 110495892 more expected))\n",
      "Error downloading 2017/ipg170509.zip: ('Connection broken: IncompleteRead(13082514 bytes read, 116078458 more expected)', IncompleteRead(13082514 bytes read, 116078458 more expected))\n",
      "Error downloading 2017/ipg170523.zip: ('Connection broken: IncompleteRead(88790346 bytes read, 42550339 more expected)', IncompleteRead(88790346 bytes read, 42550339 more expected))\n",
      "Error downloading 2017/ipg170516.zip: ('Connection broken: IncompleteRead(88285009 bytes read, 38454113 more expected)', IncompleteRead(88285009 bytes read, 38454113 more expected))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 420/835 [11:28:07<11:19:55, 98.30s/it]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "from zipfile import ZipFile, BadZipFile\n",
    "import zipfile\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "\n",
    "# Function to generate file names based on start and end years\n",
    "def generate_file_names(start_year, end_year):\n",
    "    file_names = []\n",
    "    for year in range(start_year, end_year + 1):\n",
    "        start_date = datetime(year, 1, 1)\n",
    "        days_to_tuesday = (1 - start_date.weekday() + 7) % 7 \n",
    "        tuesday = start_date + timedelta(days=days_to_tuesday)\n",
    "\n",
    "        # Iterate through all Tuesdays of the year\n",
    "        while tuesday.year == year:\n",
    "            date_str = tuesday.strftime('%y%m%d')\n",
    "            file_name = f\"ipg{date_str}.zip\"\n",
    "            file_names.append(f\"{year}/{file_name}\")\n",
    "            tuesday += timedelta(days=7)\n",
    "\n",
    "    return file_names\n",
    "\n",
    "start_year = 2009\n",
    "end_year = 2024\n",
    "filenames = generate_file_names(start_year, end_year)\n",
    "\n",
    "# Create output directory for downloaded files\n",
    "output_dir = '../Data/patent/fullpatentdata'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "base_url = 'https://bulkdata.uspto.gov/data/patent/grant/redbook/fulltext/'\n",
    "\n",
    "# Function to download files from the USPTO website with retries\n",
    "def download_file(file, max_retries=3):\n",
    "    try:\n",
    "        full_url = base_url + file\n",
    "        headers = {'User-Agent': 'Mozilla/5.0'}\n",
    "        file_path = os.path.join(output_dir, os.path.basename(file))\n",
    "\n",
    "        for attempt in range(max_retries):\n",
    "            response = requests.get(full_url, headers=headers, stream=True)\n",
    "            if response.status_code == 200:\n",
    "                # Check if the response content is a valid ZIP file\n",
    "                if response.headers.get('Content-Type') != 'application/zip':\n",
    "                    print(f\"Invalid file type for {file}\")\n",
    "                    return\n",
    "\n",
    "                with open(file_path, 'wb') as f:\n",
    "                    for chunk in response.iter_content(chunk_size=128):\n",
    "                        f.write(chunk)\n",
    "                return\n",
    "            else:\n",
    "                print(f\"Attempt {attempt + 1}: Failed to download {file} - HTTP {response.status_code}\")\n",
    "                time.sleep(2)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error downloading {file}: {e}\")\n",
    "\n",
    "# Download files using ThreadPoolExecutor for multiprocessing\n",
    "with ThreadPoolExecutor(max_workers=10) as executor:\n",
    "    list(tqdm(executor.map(download_file, filenames), total=len(filenames)))\n",
    "\n",
    "# Extracting and cleaning up zip files in parallel\n",
    "def extract_zip(filename):\n",
    "    zip_path = os.path.join(output_dir, filename)\n",
    "    try:\n",
    "        with ZipFile(zip_path, 'r') as zip_ref:\n",
    "            zip_ref.extractall(output_dir)\n",
    "        os.remove(zip_path)\n",
    "    except BadZipFile:\n",
    "        print(f\"Error: The file {filename} is not a valid zip file or is corrupted.\")\n",
    "\n",
    "zip_files = [f for f in os.listdir(output_dir) if f.endswith(\".zip\")]\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=10) as executor:\n",
    "    list(tqdm(executor.map(extract_zip, zip_files), total=len(zip_files)))\n",
    "\n",
    "print(\"Download and extraction process completed.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10(newdeep)",
   "language": "python",
   "name": "newdeep"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
