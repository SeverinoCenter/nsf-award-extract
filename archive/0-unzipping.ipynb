{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23504979",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "#show all columnsdf\n",
    "#ignore warnings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a04d805c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 9000)\n",
    "import numpy as np\n",
    "import os, sys\n",
    "import importlib\n",
    "import yaml, json\n",
    "from pathlib import Path\n",
    "base=Path('./Data/NSF-Downloads-8july2024/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e779a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>year</th>\n",
       "      <th>errors</th>\n",
       "      <th>xmlfiles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data/NSF-Downloads-8july2024/2024.zip</td>\n",
       "      <td>2024</td>\n",
       "      <td>True</td>\n",
       "      <td>8199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data/NSF-Downloads-8july2024/2018.zip</td>\n",
       "      <td>2018</td>\n",
       "      <td>True</td>\n",
       "      <td>12235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data/NSF-Downloads-8july2024/2019.zip</td>\n",
       "      <td>2019</td>\n",
       "      <td>True</td>\n",
       "      <td>13043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data/NSF-Downloads-8july2024/2009.zip</td>\n",
       "      <td>2009</td>\n",
       "      <td>True</td>\n",
       "      <td>15430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data/NSF-Downloads-8july2024/2021.zip</td>\n",
       "      <td>2021</td>\n",
       "      <td>True</td>\n",
       "      <td>12652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data/NSF-Downloads-8july2024/2020.zip</td>\n",
       "      <td>2020</td>\n",
       "      <td>True</td>\n",
       "      <td>13300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data/NSF-Downloads-8july2024/2008.zip</td>\n",
       "      <td>2008</td>\n",
       "      <td>True</td>\n",
       "      <td>12612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data/NSF-Downloads-8july2024/2022.zip</td>\n",
       "      <td>2022</td>\n",
       "      <td>True</td>\n",
       "      <td>11472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data/NSF-Downloads-8july2024/2023.zip</td>\n",
       "      <td>2023</td>\n",
       "      <td>True</td>\n",
       "      <td>11130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data/NSF-Downloads-8july2024/2012.zip</td>\n",
       "      <td>2012</td>\n",
       "      <td>True</td>\n",
       "      <td>12165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Data/NSF-Downloads-8july2024/2006.zip</td>\n",
       "      <td>2006</td>\n",
       "      <td>True</td>\n",
       "      <td>11063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Data/NSF-Downloads-8july2024/2007.zip</td>\n",
       "      <td>2007</td>\n",
       "      <td>True</td>\n",
       "      <td>12223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Data/NSF-Downloads-8july2024/2013.zip</td>\n",
       "      <td>2013</td>\n",
       "      <td>True</td>\n",
       "      <td>11502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Data/NSF-Downloads-8july2024/2005.zip</td>\n",
       "      <td>2005</td>\n",
       "      <td>True</td>\n",
       "      <td>10730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Data/NSF-Downloads-8july2024/2011.zip</td>\n",
       "      <td>2011</td>\n",
       "      <td>True</td>\n",
       "      <td>11652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Data/NSF-Downloads-8july2024/2010.zip</td>\n",
       "      <td>2010</td>\n",
       "      <td>True</td>\n",
       "      <td>13094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Data/NSF-Downloads-8july2024/2004.zip</td>\n",
       "      <td>2004</td>\n",
       "      <td>True</td>\n",
       "      <td>10721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Data/NSF-Downloads-8july2024/2000.zip</td>\n",
       "      <td>2000</td>\n",
       "      <td>True</td>\n",
       "      <td>10370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Data/NSF-Downloads-8july2024/2014.zip</td>\n",
       "      <td>2014</td>\n",
       "      <td>True</td>\n",
       "      <td>12109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Data/NSF-Downloads-8july2024/2015.zip</td>\n",
       "      <td>2015</td>\n",
       "      <td>True</td>\n",
       "      <td>13072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Data/NSF-Downloads-8july2024/2001.zip</td>\n",
       "      <td>2001</td>\n",
       "      <td>True</td>\n",
       "      <td>9848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Data/NSF-Downloads-8july2024/2017.zip</td>\n",
       "      <td>2017</td>\n",
       "      <td>True</td>\n",
       "      <td>12289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Data/NSF-Downloads-8july2024/2003.zip</td>\n",
       "      <td>2003</td>\n",
       "      <td>True</td>\n",
       "      <td>11556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Data/NSF-Downloads-8july2024/2002.zip</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>10955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Data/NSF-Downloads-8july2024/2016.zip</td>\n",
       "      <td>2016</td>\n",
       "      <td>True</td>\n",
       "      <td>12594</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     file  year  errors  xmlfiles\n",
       "0   Data/NSF-Downloads-8july2024/2024.zip  2024    True      8199\n",
       "1   Data/NSF-Downloads-8july2024/2018.zip  2018    True     12235\n",
       "2   Data/NSF-Downloads-8july2024/2019.zip  2019    True     13043\n",
       "3   Data/NSF-Downloads-8july2024/2009.zip  2009    True     15430\n",
       "4   Data/NSF-Downloads-8july2024/2021.zip  2021    True     12652\n",
       "5   Data/NSF-Downloads-8july2024/2020.zip  2020    True     13300\n",
       "6   Data/NSF-Downloads-8july2024/2008.zip  2008    True     12612\n",
       "7   Data/NSF-Downloads-8july2024/2022.zip  2022    True     11472\n",
       "8   Data/NSF-Downloads-8july2024/2023.zip  2023    True     11130\n",
       "9   Data/NSF-Downloads-8july2024/2012.zip  2012    True     12165\n",
       "10  Data/NSF-Downloads-8july2024/2006.zip  2006    True     11063\n",
       "11  Data/NSF-Downloads-8july2024/2007.zip  2007    True     12223\n",
       "12  Data/NSF-Downloads-8july2024/2013.zip  2013    True     11502\n",
       "13  Data/NSF-Downloads-8july2024/2005.zip  2005    True     10730\n",
       "14  Data/NSF-Downloads-8july2024/2011.zip  2011    True     11652\n",
       "15  Data/NSF-Downloads-8july2024/2010.zip  2010    True     13094\n",
       "16  Data/NSF-Downloads-8july2024/2004.zip  2004    True     10721\n",
       "17  Data/NSF-Downloads-8july2024/2000.zip  2000    True     10370\n",
       "18  Data/NSF-Downloads-8july2024/2014.zip  2014    True     12109\n",
       "19  Data/NSF-Downloads-8july2024/2015.zip  2015    True     13072\n",
       "20  Data/NSF-Downloads-8july2024/2001.zip  2001    True      9848\n",
       "21  Data/NSF-Downloads-8july2024/2017.zip  2017    True     12289\n",
       "22  Data/NSF-Downloads-8july2024/2003.zip  2003    True     11556\n",
       "23  Data/NSF-Downloads-8july2024/2002.zip  2002    True     10955\n",
       "24  Data/NSF-Downloads-8july2024/2016.zip  2016    True     12594"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import zipfile\n",
    "from pathlib import Path\n",
    "\n",
    "def process_zip_files(base_path, output_path, min_years):\n",
    "    \"\"\"\n",
    "    Processes ZIP files in the given base directory, extracts XML files, and returns a DataFrame\n",
    "    with information about the extracted files for years > min_years.\n",
    "    \n",
    "    Parameters:\n",
    "        base_path (Path): The base directory containing ZIP files.\n",
    "        output_path (Path): The directory where files will be temporarily extracted.\n",
    "        min_years (int): Minimum year to include in the results.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame with columns ['file', 'year', 'xmlfiles'].\n",
    "    \"\"\"\n",
    "    base = Path(base_path)\n",
    "    output = Path(output_path)\n",
    "    output.mkdir(parents=True, exist_ok=True)  # Ensure output directory exists\n",
    "    \n",
    "    zipfiles = list(base.rglob(\"*.zip\"))  # List all ZIP files in base directory\n",
    "    details = []\n",
    "    \n",
    "    for file in zipfiles:\n",
    "        file_info = {}\n",
    "        file_info['file'] = str(file)\n",
    "        \n",
    "        # Extract year from filename (assuming the year is in the filename)\n",
    "        try:\n",
    "            year = int(file.stem.split(\".\")[0])  # Adjust split logic based on actual filename format\n",
    "            file_info['year'] = int(year)\n",
    "        except ValueError:\n",
    "            print(f\"Could not extract year from filename: {file}\")\n",
    "            continue\n",
    "        \n",
    "        # Skip files with years <= min_years\n",
    "        if year <= min_years:\n",
    "            continue\n",
    "        \n",
    "        # Create a year-specific directory for extraction\n",
    "        year_dir = output / str(year)\n",
    "        year_dir.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # Extract ZIP file contents to the year-specific directory\n",
    "        try:\n",
    "            with zipfile.ZipFile(file, 'r') as zip_ref:\n",
    "                zip_ref.extractall(year_dir)\n",
    "            file_info['errors']=True\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to extract {file}: {e}\")\n",
    "            file_info['errors']=False\n",
    "            continue\n",
    "        \n",
    "        # Count the number of XML files in the year-specific directory\n",
    "        xmlfiles = list(year_dir.rglob(\"*.xml\"))\n",
    "        file_info['xmlfiles'] = len(xmlfiles)\n",
    "        \n",
    "        # Append file info to the details list\n",
    "        details.append(file_info)\n",
    "    \n",
    "    # Convert the details list into a DataFrame\n",
    "    df = pd.DataFrame(details)\n",
    "    #sort by year decending\n",
    "    df.sort_values(by='year', ascending=False, inplace=True)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    return df\n",
    "\n",
    "# Example usage\n",
    "base_path = './Data/NSF-Downloads-8july2024/'\n",
    "output_path = './temp'\n",
    "min_years = 1999  # Replace with your minimum year threshold\n",
    "\n",
    "df = process_zip_files(base_path, output_path, min_years)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68ebc231",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>year</th>\n",
       "      <th>errors</th>\n",
       "      <th>xmlfiles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data/NSF-Downloads-8july2024/2024.zip</td>\n",
       "      <td>2024</td>\n",
       "      <td>True</td>\n",
       "      <td>8199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data/NSF-Downloads-8july2024/2023.zip</td>\n",
       "      <td>2023</td>\n",
       "      <td>True</td>\n",
       "      <td>11130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data/NSF-Downloads-8july2024/2022.zip</td>\n",
       "      <td>2022</td>\n",
       "      <td>True</td>\n",
       "      <td>11472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data/NSF-Downloads-8july2024/2021.zip</td>\n",
       "      <td>2021</td>\n",
       "      <td>True</td>\n",
       "      <td>12652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data/NSF-Downloads-8july2024/2020.zip</td>\n",
       "      <td>2020</td>\n",
       "      <td>True</td>\n",
       "      <td>13300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data/NSF-Downloads-8july2024/2019.zip</td>\n",
       "      <td>2019</td>\n",
       "      <td>True</td>\n",
       "      <td>13043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data/NSF-Downloads-8july2024/2018.zip</td>\n",
       "      <td>2018</td>\n",
       "      <td>True</td>\n",
       "      <td>12235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data/NSF-Downloads-8july2024/2017.zip</td>\n",
       "      <td>2017</td>\n",
       "      <td>True</td>\n",
       "      <td>12289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data/NSF-Downloads-8july2024/2016.zip</td>\n",
       "      <td>2016</td>\n",
       "      <td>True</td>\n",
       "      <td>12594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data/NSF-Downloads-8july2024/2015.zip</td>\n",
       "      <td>2015</td>\n",
       "      <td>True</td>\n",
       "      <td>13072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Data/NSF-Downloads-8july2024/2014.zip</td>\n",
       "      <td>2014</td>\n",
       "      <td>True</td>\n",
       "      <td>12109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Data/NSF-Downloads-8july2024/2013.zip</td>\n",
       "      <td>2013</td>\n",
       "      <td>True</td>\n",
       "      <td>11502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Data/NSF-Downloads-8july2024/2012.zip</td>\n",
       "      <td>2012</td>\n",
       "      <td>True</td>\n",
       "      <td>12165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Data/NSF-Downloads-8july2024/2011.zip</td>\n",
       "      <td>2011</td>\n",
       "      <td>True</td>\n",
       "      <td>11652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Data/NSF-Downloads-8july2024/2010.zip</td>\n",
       "      <td>2010</td>\n",
       "      <td>True</td>\n",
       "      <td>13094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Data/NSF-Downloads-8july2024/2009.zip</td>\n",
       "      <td>2009</td>\n",
       "      <td>True</td>\n",
       "      <td>15430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Data/NSF-Downloads-8july2024/2008.zip</td>\n",
       "      <td>2008</td>\n",
       "      <td>True</td>\n",
       "      <td>12612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Data/NSF-Downloads-8july2024/2007.zip</td>\n",
       "      <td>2007</td>\n",
       "      <td>True</td>\n",
       "      <td>12223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Data/NSF-Downloads-8july2024/2006.zip</td>\n",
       "      <td>2006</td>\n",
       "      <td>True</td>\n",
       "      <td>11063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Data/NSF-Downloads-8july2024/2005.zip</td>\n",
       "      <td>2005</td>\n",
       "      <td>True</td>\n",
       "      <td>10730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Data/NSF-Downloads-8july2024/2004.zip</td>\n",
       "      <td>2004</td>\n",
       "      <td>True</td>\n",
       "      <td>10721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Data/NSF-Downloads-8july2024/2003.zip</td>\n",
       "      <td>2003</td>\n",
       "      <td>True</td>\n",
       "      <td>11556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Data/NSF-Downloads-8july2024/2002.zip</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>10955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Data/NSF-Downloads-8july2024/2001.zip</td>\n",
       "      <td>2001</td>\n",
       "      <td>True</td>\n",
       "      <td>9848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Data/NSF-Downloads-8july2024/2000.zip</td>\n",
       "      <td>2000</td>\n",
       "      <td>True</td>\n",
       "      <td>10370</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     file  year  errors  xmlfiles\n",
       "0   Data/NSF-Downloads-8july2024/2024.zip  2024    True      8199\n",
       "1   Data/NSF-Downloads-8july2024/2023.zip  2023    True     11130\n",
       "2   Data/NSF-Downloads-8july2024/2022.zip  2022    True     11472\n",
       "3   Data/NSF-Downloads-8july2024/2021.zip  2021    True     12652\n",
       "4   Data/NSF-Downloads-8july2024/2020.zip  2020    True     13300\n",
       "5   Data/NSF-Downloads-8july2024/2019.zip  2019    True     13043\n",
       "6   Data/NSF-Downloads-8july2024/2018.zip  2018    True     12235\n",
       "7   Data/NSF-Downloads-8july2024/2017.zip  2017    True     12289\n",
       "8   Data/NSF-Downloads-8july2024/2016.zip  2016    True     12594\n",
       "9   Data/NSF-Downloads-8july2024/2015.zip  2015    True     13072\n",
       "10  Data/NSF-Downloads-8july2024/2014.zip  2014    True     12109\n",
       "11  Data/NSF-Downloads-8july2024/2013.zip  2013    True     11502\n",
       "12  Data/NSF-Downloads-8july2024/2012.zip  2012    True     12165\n",
       "13  Data/NSF-Downloads-8july2024/2011.zip  2011    True     11652\n",
       "14  Data/NSF-Downloads-8july2024/2010.zip  2010    True     13094\n",
       "15  Data/NSF-Downloads-8july2024/2009.zip  2009    True     15430\n",
       "16  Data/NSF-Downloads-8july2024/2008.zip  2008    True     12612\n",
       "17  Data/NSF-Downloads-8july2024/2007.zip  2007    True     12223\n",
       "18  Data/NSF-Downloads-8july2024/2006.zip  2006    True     11063\n",
       "19  Data/NSF-Downloads-8july2024/2005.zip  2005    True     10730\n",
       "20  Data/NSF-Downloads-8july2024/2004.zip  2004    True     10721\n",
       "21  Data/NSF-Downloads-8july2024/2003.zip  2003    True     11556\n",
       "22  Data/NSF-Downloads-8july2024/2002.zip  2002    True     10955\n",
       "23  Data/NSF-Downloads-8july2024/2001.zip  2001    True      9848\n",
       "24  Data/NSF-Downloads-8july2024/2000.zip  2000    True     10370"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(by='year', ascending=False, inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bfd648b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xml.etree.ElementTree as ET\n",
    "import os\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "def parse_xml(file_path):\n",
    "    try:\n",
    "        tree = ET.parse(file_path)\n",
    "        root = tree.getroot()\n",
    "\n",
    "        data = {\n",
    "            'AwardID': root.findtext('.//AwardID'),\n",
    "            'AwardTitle': root.findtext('.//AwardTitle'),\n",
    "            'Agency': root.findtext('.//AGENCY'),\n",
    "            'AwardEffectiveDate': root.findtext('.//AwardEffectiveDate'),\n",
    "            'AwardExpirationDate': root.findtext('.//AwardExpirationDate'),\n",
    "            'AwardTotalIntnAmount': root.findtext('.//AwardTotalIntnAmount'),\n",
    "            'AwardAmount': root.findtext('.//AwardAmount'),\n",
    "            'AwardInstrument': root.findtext('.//AwardInstrument/Value'),\n",
    "            'Organization_Code': root.findtext('.//Organization/Code'),\n",
    "            'Directorate_Abbreviation': root.findtext('.//Directorate/Abbreviation'),\n",
    "            'Directorate_LongName': root.findtext('.//Directorate/LongName'),\n",
    "            'Division_Abbreviation': root.findtext('.//Division/Abbreviation'),\n",
    "            'Division_LongName': root.findtext('.//Division/LongName'),\n",
    "            'ProgramOfficer_Name': root.findtext('.//ProgramOfficer/SignBlockName'),\n",
    "            'ProgramOfficer_Email': root.findtext('.//ProgramOfficer/PO_EMAI'),\n",
    "            'ProgramOfficer_Phone': root.findtext('.//ProgramOfficer/PO_PHON'),\n",
    "            'AbstractNarration': root.findtext('.//AbstractNarration'),\n",
    "            'MinAmdLetterDate': root.findtext('.//MinAmdLetterDate'),\n",
    "            'MaxAmdLetterDate': root.findtext('.//MaxAmdLetterDate'),\n",
    "            'ARRAAmount': root.findtext('.//ARRAAmount'),\n",
    "            'TRAN_TYPE': root.findtext('.//TRAN_TYPE'),\n",
    "            'CFDA_NUM': root.findtext('.//CFDA_NUM'),\n",
    "            'NSF_PAR_USE_FLAG': root.findtext('.//NSF_PAR_USE_FLAG'),\n",
    "            'FUND_AGCY_CODE': root.findtext('.//FUND_AGCY_CODE'),\n",
    "            'AWDG_AGCY_CODE': root.findtext('.//AWDG_AGCY_CODE'),\n",
    "            'Investigator1_FirstName': root.findtext('.//Investigator[1]/FirstName'),\n",
    "            'Investigator1_LastName': root.findtext('.//Investigator[1]/LastName'),\n",
    "            'Investigator1_MiddleInitial': root.findtext('.//Investigator[1]/PI_MID_INIT'),\n",
    "            'Investigator1_Suffix': root.findtext('.//Investigator[1]/PI_SUFX_NAME'),\n",
    "            'Investigator1_FullName': root.findtext('.//Investigator[1]/PI_FULL_NAME'),\n",
    "            'Investigator1_Email': root.findtext('.//Investigator[1]/EmailAddress'),\n",
    "            'Investigator1_NSFID': root.findtext('.//Investigator[1]/NSF_ID'),\n",
    "            'Investigator1_StartDate': root.findtext('.//Investigator[1]/StartDate'),\n",
    "            'Investigator1_EndDate': root.findtext('.//Investigator[1]/EndDate'),\n",
    "            'Investigator1_RoleCode': root.findtext('.//Investigator[1]/RoleCode'),\n",
    "            'Investigator2_FirstName': root.findtext('.//Investigator[2]/FirstName'),\n",
    "            'Investigator2_LastName': root.findtext('.//Investigator[2]/LastName'),\n",
    "            'Investigator2_MiddleInitial': root.findtext('.//Investigator[2]/PI_MID_INIT'),\n",
    "            'Investigator2_Suffix': root.findtext('.//Investigator[2]/PI_SUFX_NAME'),\n",
    "            'Investigator2_FullName': root.findtext('.//Investigator[2]/PI_FULL_NAME'),\n",
    "            'Investigator2_Email': root.findtext('.//Investigator[2]/EmailAddress'),\n",
    "            'Investigator2_NSFID': root.findtext('.//Investigator[2]/NSF_ID'),\n",
    "            'Investigator2_StartDate': root.findtext('.//Investigator[2]/StartDate'),\n",
    "            'Investigator2_EndDate': root.findtext('.//Investigator[2]/EndDate'),\n",
    "            'Investigator2_RoleCode': root.findtext('.//Investigator[2]/RoleCode'),\n",
    "            'Investigator3_FirstName': root.findtext('.//Investigator[3]/FirstName'),\n",
    "            'Investigator3_LastName': root.findtext('.//Investigator[3]/LastName'),\n",
    "            'Investigator3_MiddleInitial': root.findtext('.//Investigator[3]/PI_MID_INIT'),\n",
    "            'Investigator3_Suffix': root.findtext('.//Investigator[3]/PI_SUFX_NAME'),\n",
    "            'Investigator3_FullName': root.findtext('.//Investigator[3]/PI_FULL_NAME'),\n",
    "            'Investigator3_Email': root.findtext('.//Investigator[3]/EmailAddress'),\n",
    "            'Investigator3_NSFID': root.findtext('.//Investigator[3]/NSF_ID'),\n",
    "            'Investigator3_StartDate': root.findtext('.//Investigator[3]/StartDate'),\n",
    "            'Investigator3_EndDate': root.findtext('.//Investigator[3]/EndDate'),\n",
    "            'Investigator3_RoleCode': root.findtext('.//Investigator[3]/RoleCode'),\n",
    "            'Institution_Name': root.findtext('.//Institution/Name'),\n",
    "            'Institution_City': root.findtext('.//Institution/CityName'),\n",
    "            'Institution_State': root.findtext('.//Institution/StateName'),\n",
    "            'Institution_Zip': root.findtext('.//Institution/ZipCode'),\n",
    "            'Institution_Country': root.findtext('.//Institution/CountryName'),\n",
    "            'Institution_Phone': root.findtext('.//Institution/PhoneNumber'),\n",
    "            'Institution_StreetAddress1': root.findtext('.//Institution/StreetAddress'),\n",
    "            'Institution_StreetAddress2': root.findtext('.//Institution/StreetAddress2'),\n",
    "            'Institution_CongressDistrict': root.findtext('.//Institution/CONGRESSDISTRICT'),\n",
    "            'Institution_CongressDistrictOrg': root.findtext('.//Institution/CONGRESS_DISTRICT_ORG'),\n",
    "            'Institution_OrgUEINum': root.findtext('.//Institution/ORG_UEI_NUM'),\n",
    "            'Institution_OrgLglBusName': root.findtext('.//Institution/ORG_LGL_BUS_NAME'),\n",
    "            'Performance_Institution_Name': root.findtext('.//Performance_Institution/Name'),\n",
    "            'Performance_Institution_City': root.findtext('.//Performance_Institution/CityName'),\n",
    "            'Performance_Institution_State': root.findtext('.//Performance_Institution/StateName'),\n",
    "            'Performance_Institution_Zip': root.findtext('.//Performance_Institution/ZipCode'),\n",
    "            'Performance_Institution_StreetAddress': root.findtext('.//Performance_Institution/StreetAddress'),\n",
    "            'Performance_Institution_CountryCode': root.findtext('.//Performance_Institution/CountryCode'),\n",
    "            'Performance_Institution_Country': root.findtext('.//Performance_Institution/CountryName'),\n",
    "            'Performance_Institution_State': root.findtext('.//Performance_Institution/StateName'),\n",
    "            'Performance_Institution_CountryFlag': root.findtext('.//Performance_Institution/CountryFlag'),\n",
    "            'Performance_Institution_CongressDistrict': root.findtext('.//Performance_Institution/CONGRESSDISTRICT'),\n",
    "            'Performance_Institution_CongressDistrictPerf': root.findtext('.//Performance_Institution/CONGRESS_DISTRICT_PERF'),\n",
    "            'ProgramElement1_Code': root.findtext('.//ProgramElement[1]/Code'),\n",
    "            'ProgramElement1_Text': root.findtext('.//ProgramElement[1]/Text'),\n",
    "            'ProgramElement2_Code': root.findtext('.//ProgramElement[2]/Code'),\n",
    "            'ProgramElement2_Text': root.findtext('.//ProgramElement[2]/Text'),\n",
    "            'ProgramElement3_Code': root.findtext('.//ProgramElement[3]/Code'),\n",
    "            'ProgramElement3_Text': root.findtext('.//ProgramElement[3]/Text'),\n",
    "            'ProgramReference_Code': root.findtext('.//ProgramReference/Code'),\n",
    "            'ProgramReference_Text': root.findtext('.//ProgramReference/Text'),\n",
    "            'Appropriation_Code': root.findtext('.//Appropriation/Code'),\n",
    "            'Appropriation_Name': root.findtext('.//Appropriation/Name'),\n",
    "            'Appropriation_SymbolID': root.findtext('.//Appropriation/APP_SYMB_ID'),\n",
    "            'Fund_Code': root.findtext('.//Fund/Code'),\n",
    "            'Fund_Name': root.findtext('.//Fund/Name'),\n",
    "            'Fund_SymbolID': root.findtext('.//Fund/FUND_SYMB_ID'),\n",
    "            'Fund_Obligation': root.findtext('.//FUND_OBLG')\n",
    "        }\n",
    "        return data\n",
    "    except ET.ParseError:\n",
    "        print(f'Error parsing file: {file_path}')\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63f3b0d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing year: 2024 with 8199 XML files...\n",
      "Processing year: 2023 with 11130 XML files...\n",
      "Processing year: 2022 with 11472 XML files...\n",
      "Error parsing file: temp/2022/49100422C0020.xml\n",
      "Processing year: 2021 with 12652 XML files...\n",
      "Processing year: 2020 with 13300 XML files...\n",
      "Processing year: 2019 with 13043 XML files...\n",
      "Processing year: 2018 with 12235 XML files...\n",
      "Processing year: 2017 with 12289 XML files...\n",
      "Processing year: 2016 with 12594 XML files...\n",
      "Processing year: 2015 with 13072 XML files...\n",
      "Processing year: 2014 with 12109 XML files...\n",
      "Processing year: 2013 with 11502 XML files...\n",
      "Processing year: 2012 with 12165 XML files...\n",
      "Error parsing file: temp/2012/1201835.xml\n",
      "Processing year: 2011 with 11652 XML files...\n",
      "Error parsing file: temp/2011/1147930.xml\n",
      "Error parsing file: temp/2011/1127340.xml\n",
      "Error parsing file: temp/2011/1117597.xml\n",
      "Error parsing file: temp/2011/1116081.xml\n",
      "Processing year: 2010 with 13094 XML files...\n",
      "Error parsing file: temp/2010/1066456.xml\n",
      "Error parsing file: temp/2010/1028076.xml\n",
      "Error parsing file: temp/2010/1028510.xml\n",
      "Error parsing file: temp/2010/1038058.xml\n",
      "Error parsing file: temp/2010/1022648.xml\n",
      "Processing year: 2009 with 15430 XML files...\n",
      "Error parsing file: temp/2009/0909203.xml\n",
      "Processing year: 2008 with 12612 XML files...\n",
      "Error parsing file: temp/2008/0834451.xml\n",
      "Error parsing file: temp/2008/0848615.xml\n",
      "Error parsing file: temp/2008/0833162.xml\n",
      "Error parsing file: temp/2008/0810982.xml\n",
      "Error parsing file: temp/2008/0803440.xml\n",
      "Error parsing file: temp/2008/0831791.xml\n",
      "Error parsing file: temp/2008/0826158.xml\n",
      "Error parsing file: temp/2008/0833126.xml\n",
      "Error parsing file: temp/2008/0840444.xml\n",
      "Processing year: 2007 with 12223 XML files...\n",
      "Error parsing file: temp/2007/0722887.xml\n",
      "Processing year: 2006 with 11063 XML files...\n",
      "Error parsing file: temp/2006/0651627.xml\n",
      "Processing year: 2005 with 10730 XML files...\n",
      "Error parsing file: temp/2005/0506732.xml\n",
      "Error parsing file: temp/2005/0507295.xml\n",
      "Processing year: 2004 with 10721 XML files...\n",
      "Error parsing file: temp/2004/0443803.xml\n",
      "Error parsing file: temp/2004/0435393.xml\n",
      "Processing year: 2003 with 11556 XML files...\n",
      "Error parsing file: temp/2003/0342388.xml\n",
      "Processing year: 2002 with 10955 XML files...\n",
      "Error parsing file: temp/2002/0231051.xml\n",
      "Error parsing file: temp/2002/0225630.xml\n",
      "Processing year: 2001 with 9848 XML files...\n",
      "Processing year: 2000 with 10370 XML files...\n",
      "Error parsing file: temp/2000/0098579.xml\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>year</th>\n",
       "      <th>errors</th>\n",
       "      <th>xmlfiles</th>\n",
       "      <th>df_rows</th>\n",
       "      <th>xml_errors</th>\n",
       "      <th>xml_error_list</th>\n",
       "      <th>time_parsed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data/NSF-Downloads-8july2024/2024.zip</td>\n",
       "      <td>2024</td>\n",
       "      <td>True</td>\n",
       "      <td>8199</td>\n",
       "      <td>8199</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>2025-01-20 14:40:26.892142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data/NSF-Downloads-8july2024/2023.zip</td>\n",
       "      <td>2023</td>\n",
       "      <td>True</td>\n",
       "      <td>11130</td>\n",
       "      <td>11130</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>2025-01-20 14:40:34.954554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data/NSF-Downloads-8july2024/2022.zip</td>\n",
       "      <td>2022</td>\n",
       "      <td>True</td>\n",
       "      <td>11472</td>\n",
       "      <td>11471</td>\n",
       "      <td>1</td>\n",
       "      <td>[PosixPath('temp/2022/49100422C0020.xml')]</td>\n",
       "      <td>2025-01-20 14:40:42.969165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data/NSF-Downloads-8july2024/2021.zip</td>\n",
       "      <td>2021</td>\n",
       "      <td>True</td>\n",
       "      <td>12652</td>\n",
       "      <td>12652</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>2025-01-20 14:40:51.825242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data/NSF-Downloads-8july2024/2020.zip</td>\n",
       "      <td>2020</td>\n",
       "      <td>True</td>\n",
       "      <td>13300</td>\n",
       "      <td>13300</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>2025-01-20 14:41:01.387771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data/NSF-Downloads-8july2024/2019.zip</td>\n",
       "      <td>2019</td>\n",
       "      <td>True</td>\n",
       "      <td>13043</td>\n",
       "      <td>13043</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>2025-01-20 14:41:11.547159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data/NSF-Downloads-8july2024/2018.zip</td>\n",
       "      <td>2018</td>\n",
       "      <td>True</td>\n",
       "      <td>12235</td>\n",
       "      <td>12235</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>2025-01-20 14:41:20.727974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data/NSF-Downloads-8july2024/2017.zip</td>\n",
       "      <td>2017</td>\n",
       "      <td>True</td>\n",
       "      <td>12289</td>\n",
       "      <td>12289</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>2025-01-20 14:41:29.909602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data/NSF-Downloads-8july2024/2016.zip</td>\n",
       "      <td>2016</td>\n",
       "      <td>True</td>\n",
       "      <td>12594</td>\n",
       "      <td>12594</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>2025-01-20 14:41:40.477871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data/NSF-Downloads-8july2024/2015.zip</td>\n",
       "      <td>2015</td>\n",
       "      <td>True</td>\n",
       "      <td>13072</td>\n",
       "      <td>13072</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>2025-01-20 14:41:50.074970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Data/NSF-Downloads-8july2024/2014.zip</td>\n",
       "      <td>2014</td>\n",
       "      <td>True</td>\n",
       "      <td>12109</td>\n",
       "      <td>12109</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>2025-01-20 14:41:58.959041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Data/NSF-Downloads-8july2024/2013.zip</td>\n",
       "      <td>2013</td>\n",
       "      <td>True</td>\n",
       "      <td>11502</td>\n",
       "      <td>11502</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>2025-01-20 14:42:07.422153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Data/NSF-Downloads-8july2024/2012.zip</td>\n",
       "      <td>2012</td>\n",
       "      <td>True</td>\n",
       "      <td>12165</td>\n",
       "      <td>12164</td>\n",
       "      <td>1</td>\n",
       "      <td>[PosixPath('temp/2012/1201835.xml')]</td>\n",
       "      <td>2025-01-20 14:42:16.592702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Data/NSF-Downloads-8july2024/2011.zip</td>\n",
       "      <td>2011</td>\n",
       "      <td>True</td>\n",
       "      <td>11652</td>\n",
       "      <td>11648</td>\n",
       "      <td>4</td>\n",
       "      <td>[PosixPath('temp/2011/1147930.xml'), PosixPath...</td>\n",
       "      <td>2025-01-20 14:42:25.862997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Data/NSF-Downloads-8july2024/2010.zip</td>\n",
       "      <td>2010</td>\n",
       "      <td>True</td>\n",
       "      <td>13094</td>\n",
       "      <td>13089</td>\n",
       "      <td>5</td>\n",
       "      <td>[PosixPath('temp/2010/1066456.xml'), PosixPath...</td>\n",
       "      <td>2025-01-20 14:42:35.716885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Data/NSF-Downloads-8july2024/2009.zip</td>\n",
       "      <td>2009</td>\n",
       "      <td>True</td>\n",
       "      <td>15430</td>\n",
       "      <td>15429</td>\n",
       "      <td>1</td>\n",
       "      <td>[PosixPath('temp/2009/0909203.xml')]</td>\n",
       "      <td>2025-01-20 14:42:46.894633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Data/NSF-Downloads-8july2024/2008.zip</td>\n",
       "      <td>2008</td>\n",
       "      <td>True</td>\n",
       "      <td>12612</td>\n",
       "      <td>12603</td>\n",
       "      <td>9</td>\n",
       "      <td>[PosixPath('temp/2008/0834451.xml'), PosixPath...</td>\n",
       "      <td>2025-01-20 14:42:56.416240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Data/NSF-Downloads-8july2024/2007.zip</td>\n",
       "      <td>2007</td>\n",
       "      <td>True</td>\n",
       "      <td>12223</td>\n",
       "      <td>12222</td>\n",
       "      <td>1</td>\n",
       "      <td>[PosixPath('temp/2007/0722887.xml')]</td>\n",
       "      <td>2025-01-20 14:43:05.208167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Data/NSF-Downloads-8july2024/2006.zip</td>\n",
       "      <td>2006</td>\n",
       "      <td>True</td>\n",
       "      <td>11063</td>\n",
       "      <td>11062</td>\n",
       "      <td>1</td>\n",
       "      <td>[PosixPath('temp/2006/0651627.xml')]</td>\n",
       "      <td>2025-01-20 14:43:13.229464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Data/NSF-Downloads-8july2024/2005.zip</td>\n",
       "      <td>2005</td>\n",
       "      <td>True</td>\n",
       "      <td>10730</td>\n",
       "      <td>10728</td>\n",
       "      <td>2</td>\n",
       "      <td>[PosixPath('temp/2005/0506732.xml'), PosixPath...</td>\n",
       "      <td>2025-01-20 14:43:20.637136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Data/NSF-Downloads-8july2024/2004.zip</td>\n",
       "      <td>2004</td>\n",
       "      <td>True</td>\n",
       "      <td>10721</td>\n",
       "      <td>10719</td>\n",
       "      <td>2</td>\n",
       "      <td>[PosixPath('temp/2004/0443803.xml'), PosixPath...</td>\n",
       "      <td>2025-01-20 14:43:27.813912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Data/NSF-Downloads-8july2024/2003.zip</td>\n",
       "      <td>2003</td>\n",
       "      <td>True</td>\n",
       "      <td>11556</td>\n",
       "      <td>11555</td>\n",
       "      <td>1</td>\n",
       "      <td>[PosixPath('temp/2003/0342388.xml')]</td>\n",
       "      <td>2025-01-20 14:43:35.401614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Data/NSF-Downloads-8july2024/2002.zip</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>10955</td>\n",
       "      <td>10953</td>\n",
       "      <td>2</td>\n",
       "      <td>[PosixPath('temp/2002/0231051.xml'), PosixPath...</td>\n",
       "      <td>2025-01-20 14:43:42.850563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Data/NSF-Downloads-8july2024/2001.zip</td>\n",
       "      <td>2001</td>\n",
       "      <td>True</td>\n",
       "      <td>9848</td>\n",
       "      <td>9848</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>2025-01-20 14:43:49.509336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Data/NSF-Downloads-8july2024/2000.zip</td>\n",
       "      <td>2000</td>\n",
       "      <td>True</td>\n",
       "      <td>10370</td>\n",
       "      <td>10369</td>\n",
       "      <td>1</td>\n",
       "      <td>[PosixPath('temp/2000/0098579.xml')]</td>\n",
       "      <td>2025-01-20 14:43:56.489119</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     file  year  errors  xmlfiles  df_rows  \\\n",
       "0   Data/NSF-Downloads-8july2024/2024.zip  2024    True      8199     8199   \n",
       "1   Data/NSF-Downloads-8july2024/2023.zip  2023    True     11130    11130   \n",
       "2   Data/NSF-Downloads-8july2024/2022.zip  2022    True     11472    11471   \n",
       "3   Data/NSF-Downloads-8july2024/2021.zip  2021    True     12652    12652   \n",
       "4   Data/NSF-Downloads-8july2024/2020.zip  2020    True     13300    13300   \n",
       "5   Data/NSF-Downloads-8july2024/2019.zip  2019    True     13043    13043   \n",
       "6   Data/NSF-Downloads-8july2024/2018.zip  2018    True     12235    12235   \n",
       "7   Data/NSF-Downloads-8july2024/2017.zip  2017    True     12289    12289   \n",
       "8   Data/NSF-Downloads-8july2024/2016.zip  2016    True     12594    12594   \n",
       "9   Data/NSF-Downloads-8july2024/2015.zip  2015    True     13072    13072   \n",
       "10  Data/NSF-Downloads-8july2024/2014.zip  2014    True     12109    12109   \n",
       "11  Data/NSF-Downloads-8july2024/2013.zip  2013    True     11502    11502   \n",
       "12  Data/NSF-Downloads-8july2024/2012.zip  2012    True     12165    12164   \n",
       "13  Data/NSF-Downloads-8july2024/2011.zip  2011    True     11652    11648   \n",
       "14  Data/NSF-Downloads-8july2024/2010.zip  2010    True     13094    13089   \n",
       "15  Data/NSF-Downloads-8july2024/2009.zip  2009    True     15430    15429   \n",
       "16  Data/NSF-Downloads-8july2024/2008.zip  2008    True     12612    12603   \n",
       "17  Data/NSF-Downloads-8july2024/2007.zip  2007    True     12223    12222   \n",
       "18  Data/NSF-Downloads-8july2024/2006.zip  2006    True     11063    11062   \n",
       "19  Data/NSF-Downloads-8july2024/2005.zip  2005    True     10730    10728   \n",
       "20  Data/NSF-Downloads-8july2024/2004.zip  2004    True     10721    10719   \n",
       "21  Data/NSF-Downloads-8july2024/2003.zip  2003    True     11556    11555   \n",
       "22  Data/NSF-Downloads-8july2024/2002.zip  2002    True     10955    10953   \n",
       "23  Data/NSF-Downloads-8july2024/2001.zip  2001    True      9848     9848   \n",
       "24  Data/NSF-Downloads-8july2024/2000.zip  2000    True     10370    10369   \n",
       "\n",
       "    xml_errors                                     xml_error_list  \\\n",
       "0            0                                                 []   \n",
       "1            0                                                 []   \n",
       "2            1         [PosixPath('temp/2022/49100422C0020.xml')]   \n",
       "3            0                                                 []   \n",
       "4            0                                                 []   \n",
       "5            0                                                 []   \n",
       "6            0                                                 []   \n",
       "7            0                                                 []   \n",
       "8            0                                                 []   \n",
       "9            0                                                 []   \n",
       "10           0                                                 []   \n",
       "11           0                                                 []   \n",
       "12           1               [PosixPath('temp/2012/1201835.xml')]   \n",
       "13           4  [PosixPath('temp/2011/1147930.xml'), PosixPath...   \n",
       "14           5  [PosixPath('temp/2010/1066456.xml'), PosixPath...   \n",
       "15           1               [PosixPath('temp/2009/0909203.xml')]   \n",
       "16           9  [PosixPath('temp/2008/0834451.xml'), PosixPath...   \n",
       "17           1               [PosixPath('temp/2007/0722887.xml')]   \n",
       "18           1               [PosixPath('temp/2006/0651627.xml')]   \n",
       "19           2  [PosixPath('temp/2005/0506732.xml'), PosixPath...   \n",
       "20           2  [PosixPath('temp/2004/0443803.xml'), PosixPath...   \n",
       "21           1               [PosixPath('temp/2003/0342388.xml')]   \n",
       "22           2  [PosixPath('temp/2002/0231051.xml'), PosixPath...   \n",
       "23           0                                                 []   \n",
       "24           1               [PosixPath('temp/2000/0098579.xml')]   \n",
       "\n",
       "                   time_parsed  \n",
       "0   2025-01-20 14:40:26.892142  \n",
       "1   2025-01-20 14:40:34.954554  \n",
       "2   2025-01-20 14:40:42.969165  \n",
       "3   2025-01-20 14:40:51.825242  \n",
       "4   2025-01-20 14:41:01.387771  \n",
       "5   2025-01-20 14:41:11.547159  \n",
       "6   2025-01-20 14:41:20.727974  \n",
       "7   2025-01-20 14:41:29.909602  \n",
       "8   2025-01-20 14:41:40.477871  \n",
       "9   2025-01-20 14:41:50.074970  \n",
       "10  2025-01-20 14:41:58.959041  \n",
       "11  2025-01-20 14:42:07.422153  \n",
       "12  2025-01-20 14:42:16.592702  \n",
       "13  2025-01-20 14:42:25.862997  \n",
       "14  2025-01-20 14:42:35.716885  \n",
       "15  2025-01-20 14:42:46.894633  \n",
       "16  2025-01-20 14:42:56.416240  \n",
       "17  2025-01-20 14:43:05.208167  \n",
       "18  2025-01-20 14:43:13.229464  \n",
       "19  2025-01-20 14:43:20.637136  \n",
       "20  2025-01-20 14:43:27.813912  \n",
       "21  2025-01-20 14:43:35.401614  \n",
       "22  2025-01-20 14:43:42.850563  \n",
       "23  2025-01-20 14:43:49.509336  \n",
       "24  2025-01-20 14:43:56.489119  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "def collect_data_from_xml_files(root_folder, year):\n",
    "    data_list = []\n",
    "    error_files = []\n",
    "    yr_folder = root_folder / str(year)\n",
    "    xmlfiles = list(yr_folder.rglob(\"*.xml\"))\n",
    "    \n",
    "    for filename in xmlfiles:\n",
    "        # Assuming parse_xml is a user-defined function to parse XML files\n",
    "        data = parse_xml(filename)  # Use filename directly as it contains the full path\n",
    "        \n",
    "        if data is not None:\n",
    "            data['Year'] = year\n",
    "            data_list.append(data)\n",
    "        else:\n",
    "            error_files.append(filename)\n",
    "    \n",
    "    return pd.DataFrame(data_list), error_files\n",
    "\n",
    "# Define the root folder and output directories\n",
    "root_folder = Path('./temp')\n",
    "output_csv = Path('./outputcsv')\n",
    "output_pkl = Path('./outputpkl')\n",
    "\n",
    "# Ensure output directories exist\n",
    "output_csv.mkdir(parents=True, exist_ok=True)\n",
    "output_pkl.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Add new columns to the DataFrame\n",
    "df['df_rows'] = 0\n",
    "df['xml_errors'] = 0\n",
    "df['xml_error_list'] = None\n",
    "df['time_parsed'] = None\n",
    "\n",
    "# Iterate through the DataFrame and process XML files\n",
    "for index, row in df.iterrows():\n",
    "    print(f\"Processing year: {row['year']} with {row['xmlfiles']} XML files...\")\n",
    "    \n",
    "    # Collect data and errors from XML files\n",
    "    data, error_files = collect_data_from_xml_files(root_folder, row['year'])\n",
    "    \n",
    "    # Update the DataFrame with new information\n",
    "    df.loc[index, 'df_rows'] = len(data)\n",
    "    df.loc[index, 'xml_errors'] = len(error_files)\n",
    "    df.loc[index, 'xml_error_list'] = str(error_files)\n",
    "    df.loc[index, 'time_parsed'] = datetime.now()\n",
    "    \n",
    "    # Save the processed data\n",
    "    if not data.empty:\n",
    "        data.to_csv(output_csv / f'{row[\"year\"]}.csv', index=False)\n",
    "        data.to_pickle(output_pkl / f'{row[\"year\"]}.pkl')\n",
    "\n",
    "# Output the final DataFrame\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "901a2056",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('0_processing.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b22aec40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing year: 2024 with 8199 XML files...\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "NDFrame.to_pickle() got an unexpected keyword argument 'index'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mall\u001b[39m\u001b[38;5;241m=\u001b[39mpd\u001b[38;5;241m.\u001b[39mconcat([\u001b[38;5;28mall\u001b[39m, tmp])\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mall\u001b[39m\u001b[38;5;241m.\u001b[39mto_csv(output_csv\u001b[38;5;241m/\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mall.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)  \n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;43mall\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_pickle\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_pkl\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mall.pkl\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m   \n",
      "\u001b[0;31mTypeError\u001b[0m: NDFrame.to_pickle() got an unexpected keyword argument 'index'"
     ]
    }
   ],
   "source": [
    "#iterate over the df and read the pickle files to a single dataframe\n",
    "all=pd.DataFrame()\n",
    "for index, row in df.iterrows():\n",
    "    print(f\"Processing year: {row['year']} with {row['xmlfiles']} XML files...\")\n",
    "    tmp=pd.read_pickle(output_pkl / f'{row[\"year\"]}.pkl')\n",
    "    all=pd.concat([all, tmp])\n",
    "all.to_csv(output_csv/'all.csv', index=False)  \n",
    "all.to_pickle(output_pkl/'all.pkl')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "12c4177a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024 8199\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'temp/2024/temp/2024/2428698.xml'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 25\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;28mprint\u001b[39m(row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124myear\u001b[39m\u001b[38;5;124m'\u001b[39m], row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mxmlfiles\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# Collect data and create DataFrame\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m     data, error_files \u001b[38;5;241m=\u001b[39m \u001b[43mcollect_data_from_xml_files\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroot_folder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43myear\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;66;03m#create the directory if it doesn't exist ./output/csv\u001b[39;00m\n\u001b[1;32m     27\u001b[0m     output_csv\u001b[38;5;241m.\u001b[39mmkdir(parents\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[11], line 7\u001b[0m, in \u001b[0;36mcollect_data_from_xml_files\u001b[0;34m(root_folder, year)\u001b[0m\n\u001b[1;32m      5\u001b[0m xmlfiles \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(yr_folder\u001b[38;5;241m.\u001b[39mrglob(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*.xml\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m filename \u001b[38;5;129;01min\u001b[39;00m xmlfiles:\n\u001b[0;32m----> 7\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mparse_xml\u001b[49m\u001b[43m(\u001b[49m\u001b[43myr_folder\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     10\u001b[0m         data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mYear\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m year\n",
      "Cell \u001b[0;32mIn[8], line 8\u001b[0m, in \u001b[0;36mparse_xml\u001b[0;34m(file_path)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparse_xml\u001b[39m(file_path):\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m----> 8\u001b[0m         tree \u001b[38;5;241m=\u001b[39m \u001b[43mET\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m         root \u001b[38;5;241m=\u001b[39m tree\u001b[38;5;241m.\u001b[39mgetroot()\n\u001b[1;32m     11\u001b[0m         data \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     12\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAwardID\u001b[39m\u001b[38;5;124m'\u001b[39m: root\u001b[38;5;241m.\u001b[39mfindtext(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.//AwardID\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[1;32m     13\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAwardTitle\u001b[39m\u001b[38;5;124m'\u001b[39m: root\u001b[38;5;241m.\u001b[39mfindtext(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.//AwardTitle\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    104\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFund_Obligation\u001b[39m\u001b[38;5;124m'\u001b[39m: root\u001b[38;5;241m.\u001b[39mfindtext(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.//FUND_OBLG\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    105\u001b[0m         }\n",
      "File \u001b[0;32m~/anaconda3/envs/llm/lib/python3.10/xml/etree/ElementTree.py:1222\u001b[0m, in \u001b[0;36mparse\u001b[0;34m(source, parser)\u001b[0m\n\u001b[1;32m   1213\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Parse XML document into element tree.\u001b[39;00m\n\u001b[1;32m   1214\u001b[0m \n\u001b[1;32m   1215\u001b[0m \u001b[38;5;124;03m*source* is a filename or file object containing XML data,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1219\u001b[0m \n\u001b[1;32m   1220\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1221\u001b[0m tree \u001b[38;5;241m=\u001b[39m ElementTree()\n\u001b[0;32m-> 1222\u001b[0m \u001b[43mtree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparser\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1223\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tree\n",
      "File \u001b[0;32m~/anaconda3/envs/llm/lib/python3.10/xml/etree/ElementTree.py:569\u001b[0m, in \u001b[0;36mElementTree.parse\u001b[0;34m(self, source, parser)\u001b[0m\n\u001b[1;32m    567\u001b[0m close_source \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    568\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(source, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mread\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 569\u001b[0m     source \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    570\u001b[0m     close_source \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    571\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'temp/2024/temp/2024/2428698.xml'"
     ]
    }
   ],
   "source": [
    "\n",
    "def collect_data_from_xml_files(root_folder, year):\n",
    "    data_list = []\n",
    "    error_files = []\n",
    "    yr_folder=root_folder/str(year)\n",
    "    xmlfiles = list(yr_folder.rglob(\"*.xml\"))\n",
    "    for filename in xmlfiles:\n",
    "        data = parse_xml(yr_folder/filename)\n",
    "\n",
    "        if data is not None:\n",
    "            data['Year'] = year\n",
    "            data_list.append(data)\n",
    "        else:\n",
    "            error_files.append(file_path)\n",
    "\n",
    "    return pd.DataFrame(data_list), error_files\n",
    "\n",
    "# Define the root folder where the year folders are located\n",
    "root_folder = Path('./temp')\n",
    "output_csv = Path('./outputcsv')\n",
    "output_csv = Path('./outputpkl')\n",
    "#iterate through the dataframe df\n",
    "for index, row in df.iterrows():\n",
    "    print(row['year'], row['xmlfiles'])\n",
    "# Collect data and create DataFrame\n",
    "    data, error_files = collect_data_from_xml_files(root_folder, row['year'])\n",
    "    #create the directory if it doesn't exist ./output/csv\n",
    "    output_csv.mkdir(parents=True, exist_ok=True)\n",
    "    output_pkl.mkdir(parents=True, exist_ok=True)\n",
    "    df.loc[index, 'df_rows'] = len(data)\n",
    "    df.loc[index, 'xml_errors'] = len(error_files)\n",
    "    df.loc[index, 'xml_error_list'] = len(errors)\n",
    "    df['time_parsed'] = datetime.now()\n",
    "    data.to_csv(output_csv/f'{row[\"year\"]}.csv', index=False)\n",
    "    data.to_pickle(output_pkl/f'{row[\"year\"]}.pkl')\n",
    "    \n",
    "    # Get the current date and time\n",
    "    \n",
    "df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7c650f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully saved to output_data_20250120_125616.csv\n",
      "Error log saved to error_log_20250120_125616.csv\n",
      "Successfully parsed XML files: 19329\n",
      "Files with errors: 0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import xml.etree.ElementTree as ET\n",
    "import os\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "def parse_xml(file_path):\n",
    "    try:\n",
    "        tree = ET.parse(file_path)\n",
    "        root = tree.getroot()\n",
    "\n",
    "        data = {\n",
    "            'AwardID': root.findtext('.//AwardID'),\n",
    "            'AwardTitle': root.findtext('.//AwardTitle'),\n",
    "            'Agency': root.findtext('.//AGENCY'),\n",
    "            'AwardEffectiveDate': root.findtext('.//AwardEffectiveDate'),\n",
    "            'AwardExpirationDate': root.findtext('.//AwardExpirationDate'),\n",
    "            'AwardTotalIntnAmount': root.findtext('.//AwardTotalIntnAmount'),\n",
    "            'AwardAmount': root.findtext('.//AwardAmount'),\n",
    "            'AwardInstrument': root.findtext('.//AwardInstrument/Value'),\n",
    "            'Organization_Code': root.findtext('.//Organization/Code'),\n",
    "            'Directorate_Abbreviation': root.findtext('.//Directorate/Abbreviation'),\n",
    "            'Directorate_LongName': root.findtext('.//Directorate/LongName'),\n",
    "            'Division_Abbreviation': root.findtext('.//Division/Abbreviation'),\n",
    "            'Division_LongName': root.findtext('.//Division/LongName'),\n",
    "            'ProgramOfficer_Name': root.findtext('.//ProgramOfficer/SignBlockName'),\n",
    "            'ProgramOfficer_Email': root.findtext('.//ProgramOfficer/PO_EMAI'),\n",
    "            'ProgramOfficer_Phone': root.findtext('.//ProgramOfficer/PO_PHON'),\n",
    "            'AbstractNarration': root.findtext('.//AbstractNarration'),\n",
    "            'MinAmdLetterDate': root.findtext('.//MinAmdLetterDate'),\n",
    "            'MaxAmdLetterDate': root.findtext('.//MaxAmdLetterDate'),\n",
    "            'ARRAAmount': root.findtext('.//ARRAAmount'),\n",
    "            'TRAN_TYPE': root.findtext('.//TRAN_TYPE'),\n",
    "            'CFDA_NUM': root.findtext('.//CFDA_NUM'),\n",
    "            'NSF_PAR_USE_FLAG': root.findtext('.//NSF_PAR_USE_FLAG'),\n",
    "            'FUND_AGCY_CODE': root.findtext('.//FUND_AGCY_CODE'),\n",
    "            'AWDG_AGCY_CODE': root.findtext('.//AWDG_AGCY_CODE'),\n",
    "            'Investigator1_FirstName': root.findtext('.//Investigator[1]/FirstName'),\n",
    "            'Investigator1_LastName': root.findtext('.//Investigator[1]/LastName'),\n",
    "            'Investigator1_MiddleInitial': root.findtext('.//Investigator[1]/PI_MID_INIT'),\n",
    "            'Investigator1_Suffix': root.findtext('.//Investigator[1]/PI_SUFX_NAME'),\n",
    "            'Investigator1_FullName': root.findtext('.//Investigator[1]/PI_FULL_NAME'),\n",
    "            'Investigator1_Email': root.findtext('.//Investigator[1]/EmailAddress'),\n",
    "            'Investigator1_NSFID': root.findtext('.//Investigator[1]/NSF_ID'),\n",
    "            'Investigator1_StartDate': root.findtext('.//Investigator[1]/StartDate'),\n",
    "            'Investigator1_EndDate': root.findtext('.//Investigator[1]/EndDate'),\n",
    "            'Investigator1_RoleCode': root.findtext('.//Investigator[1]/RoleCode'),\n",
    "            'Investigator2_FirstName': root.findtext('.//Investigator[2]/FirstName'),\n",
    "            'Investigator2_LastName': root.findtext('.//Investigator[2]/LastName'),\n",
    "            'Investigator2_MiddleInitial': root.findtext('.//Investigator[2]/PI_MID_INIT'),\n",
    "            'Investigator2_Suffix': root.findtext('.//Investigator[2]/PI_SUFX_NAME'),\n",
    "            'Investigator2_FullName': root.findtext('.//Investigator[2]/PI_FULL_NAME'),\n",
    "            'Investigator2_Email': root.findtext('.//Investigator[2]/EmailAddress'),\n",
    "            'Investigator2_NSFID': root.findtext('.//Investigator[2]/NSF_ID'),\n",
    "            'Investigator2_StartDate': root.findtext('.//Investigator[2]/StartDate'),\n",
    "            'Investigator2_EndDate': root.findtext('.//Investigator[2]/EndDate'),\n",
    "            'Investigator2_RoleCode': root.findtext('.//Investigator[2]/RoleCode'),\n",
    "            'Investigator3_FirstName': root.findtext('.//Investigator[3]/FirstName'),\n",
    "            'Investigator3_LastName': root.findtext('.//Investigator[3]/LastName'),\n",
    "            'Investigator3_MiddleInitial': root.findtext('.//Investigator[3]/PI_MID_INIT'),\n",
    "            'Investigator3_Suffix': root.findtext('.//Investigator[3]/PI_SUFX_NAME'),\n",
    "            'Investigator3_FullName': root.findtext('.//Investigator[3]/PI_FULL_NAME'),\n",
    "            'Investigator3_Email': root.findtext('.//Investigator[3]/EmailAddress'),\n",
    "            'Investigator3_NSFID': root.findtext('.//Investigator[3]/NSF_ID'),\n",
    "            'Investigator3_StartDate': root.findtext('.//Investigator[3]/StartDate'),\n",
    "            'Investigator3_EndDate': root.findtext('.//Investigator[3]/EndDate'),\n",
    "            'Investigator3_RoleCode': root.findtext('.//Investigator[3]/RoleCode'),\n",
    "            'Institution_Name': root.findtext('.//Institution/Name'),\n",
    "            'Institution_City': root.findtext('.//Institution/CityName'),\n",
    "            'Institution_State': root.findtext('.//Institution/StateName'),\n",
    "            'Institution_Zip': root.findtext('.//Institution/ZipCode'),\n",
    "            'Institution_Country': root.findtext('.//Institution/CountryName'),\n",
    "            'Institution_Phone': root.findtext('.//Institution/PhoneNumber'),\n",
    "            'Institution_StreetAddress1': root.findtext('.//Institution/StreetAddress'),\n",
    "            'Institution_StreetAddress2': root.findtext('.//Institution/StreetAddress2'),\n",
    "            'Institution_CongressDistrict': root.findtext('.//Institution/CONGRESSDISTRICT'),\n",
    "            'Institution_CongressDistrictOrg': root.findtext('.//Institution/CONGRESS_DISTRICT_ORG'),\n",
    "            'Institution_OrgUEINum': root.findtext('.//Institution/ORG_UEI_NUM'),\n",
    "            'Institution_OrgLglBusName': root.findtext('.//Institution/ORG_LGL_BUS_NAME'),\n",
    "            'Performance_Institution_Name': root.findtext('.//Performance_Institution/Name'),\n",
    "            'Performance_Institution_City': root.findtext('.//Performance_Institution/CityName'),\n",
    "            'Performance_Institution_State': root.findtext('.//Performance_Institution/StateName'),\n",
    "            'Performance_Institution_Zip': root.findtext('.//Performance_Institution/ZipCode'),\n",
    "            'Performance_Institution_StreetAddress': root.findtext('.//Performance_Institution/StreetAddress'),\n",
    "            'Performance_Institution_CountryCode': root.findtext('.//Performance_Institution/CountryCode'),\n",
    "            'Performance_Institution_Country': root.findtext('.//Performance_Institution/CountryName'),\n",
    "            'Performance_Institution_State': root.findtext('.//Performance_Institution/StateName'),\n",
    "            'Performance_Institution_CountryFlag': root.findtext('.//Performance_Institution/CountryFlag'),\n",
    "            'Performance_Institution_CongressDistrict': root.findtext('.//Performance_Institution/CONGRESSDISTRICT'),\n",
    "            'Performance_Institution_CongressDistrictPerf': root.findtext('.//Performance_Institution/CONGRESS_DISTRICT_PERF'),\n",
    "            'ProgramElement1_Code': root.findtext('.//ProgramElement[1]/Code'),\n",
    "            'ProgramElement1_Text': root.findtext('.//ProgramElement[1]/Text'),\n",
    "            'ProgramElement2_Code': root.findtext('.//ProgramElement[2]/Code'),\n",
    "            'ProgramElement2_Text': root.findtext('.//ProgramElement[2]/Text'),\n",
    "            'ProgramElement3_Code': root.findtext('.//ProgramElement[3]/Code'),\n",
    "            'ProgramElement3_Text': root.findtext('.//ProgramElement[3]/Text'),\n",
    "            'ProgramReference_Code': root.findtext('.//ProgramReference/Code'),\n",
    "            'ProgramReference_Text': root.findtext('.//ProgramReference/Text'),\n",
    "            'Appropriation_Code': root.findtext('.//Appropriation/Code'),\n",
    "            'Appropriation_Name': root.findtext('.//Appropriation/Name'),\n",
    "            'Appropriation_SymbolID': root.findtext('.//Appropriation/APP_SYMB_ID'),\n",
    "            'Fund_Code': root.findtext('.//Fund/Code'),\n",
    "            'Fund_Name': root.findtext('.//Fund/Name'),\n",
    "            'Fund_SymbolID': root.findtext('.//Fund/FUND_SYMB_ID'),\n",
    "            'Fund_Obligation': root.findtext('.//FUND_OBLG')\n",
    "        }\n",
    "        return data\n",
    "    except ET.ParseError:\n",
    "        print(f'Error parsing file: {file_path}')\n",
    "        return None\n",
    "\n",
    "def collect_data_from_xml_files(root_folder):\n",
    "    data_list = []\n",
    "    error_files = []\n",
    "\n",
    "    for year_folder in os.listdir(root_folder):\n",
    "        year_path = os.path.join(root_folder, year_folder)\n",
    "        if os.path.isdir(year_path):  # Ensure it's a directory\n",
    "            for filename in os.listdir(year_path):\n",
    "                if filename.endswith('.xml'):\n",
    "                    file_path = os.path.join(year_path, filename)\n",
    "                    data = parse_xml(file_path)\n",
    "                    if data is not None:\n",
    "                        data['Year'] = year_folder\n",
    "                        data_list.append(data)\n",
    "                    else:\n",
    "                        error_files.append(file_path)\n",
    "\n",
    "    return pd.DataFrame(data_list), error_files\n",
    "\n",
    "# Define the root folder where the year folders are located\n",
    "root_folder = './temp'\n",
    "\n",
    "# Collect data and create DataFrame\n",
    "df, error_files = collect_data_from_xml_files(root_folder)\n",
    "\n",
    "# Get the current date and time\n",
    "now = datetime.now()\n",
    "date_time_str = now.strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "# Save the DataFrame to a CSV file with date and time in the filename\n",
    "output_csv_path = f'output_data_{date_time_str}.csv'\n",
    "df.to_csv(output_csv_path, index=False)\n",
    "\n",
    "# Save the error log to a CSV file with date and time in the filename\n",
    "error_log_path = f'error_log_{date_time_str}.csv'\n",
    "pd.DataFrame(error_files, columns=['FilePath']).to_csv(error_log_path, index=False)\n",
    "\n",
    "print(f'Data successfully saved to {output_csv_path}')\n",
    "print(f'Error log saved to {error_log_path}')\n",
    "print(f'Successfully parsed XML files: {len(df)}')\n",
    "print(f'Files with errors: {len(error_files)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10(llm)",
   "language": "python",
   "name": "llm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
